# üß¨ DNA Barcoding with De Bruijn Graphs and GNNs

A PyTorch Geometric project that integrates **De Bruijn graph** representations with **direction-aware Graph Neural Networks (GNNs)** for accurate and scalable classification of DNA barcode sequences. Developed as part of the Deep Learning course at the University of Padova.

## üìò Overview

This project proposes a novel framework that transforms DNA sequences into De Bruijn graphs and applies a directional GATv2-based GNN to classify species. It leverages:

- One-hot encoded k-mers as **node features**
- Sinusoidal **positional encoding** as edge features
- Dual-direction GAT layers for better **message passing**
- Global mean/sum/max pooling and MLP for **graph-level prediction**

The approach shows strong generalization and achieves high accuracy on diverse DNA barcode datasets such as **bats**, **birds**, **fishes**, **Inga**, and **Cypraeidae**.

## üìà Key Results

| Dataset     | Accuracy | Precision | Recall | R¬≤ Score |
|-------------|----------|-----------|--------|----------|
| Bats        | 99.3%    | 0.996     | 0.996  | 0.988    |
| Fishes      | 99.1%    | 0.972     | 0.981  | 0.955    |
| Cypraeidae  | 94.3%    | 0.893     | 0.897  | 0.998    |
| Inga        | 88.4%    | 0.823     | 0.837  | 0.715    |
| Birds       | 86.4%    | 0.736     | 0.768  | 0.725    |

## üß™ Datasets

Each dataset contains DNA barcode sequences labeled by species. The sequences vary in length and number of classes. De Bruijn graphs are constructed using different `k` values (3, 4, 5), with best results for `k = 5`.

Example dataset:
- **Bats:** 95 classes, 839 samples, sequence length: 657 bp

## üß¨ Graph Construction

- Nodes = unique (k‚àí1)-mers  
- Edges = k-mer overlaps (directed)  
- Node Features = One-hot encoding (A, C, G, T)  
- Edge Features = Sinusoidal positional encoding  

## üß† Model Architecture

- **GNN Backbone:** 8 stacked GATv2 layers with forward/backward directional separation
- **Pooling:** Mean, Sum, Max (concatenated)
- **MLP Classifier:** Deep MLP with layers [512, 1024, 2048]
- **Optimizer:** AdamW  
- **Scheduler:** CosineAnnealingLR  
- **Loss:** CrossEntropy

## ‚öôÔ∏è Hyperparameters

```python
learning_rate = 0.001
batch_size = 32
k = 5
positional_encoding_dim = 128
gnn_hidden_layers = [256] * 8
linear_hidden_layers = [512, 1024, 2048]
weight_decay = 1e-5
